{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](./images/colab-badge.png)](https://colab.research.google.com/github/abrsvn/pyactr-book/blob/master/notebooks/32_spreading_activation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 400\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_activation(pres_times, moments):\n",
    "    base_act = np.zeros(len(moments))\n",
    "    for idx in range(len(moments)):\n",
    "        past_pres_times = pres_times[pres_times<moments[idx]]\n",
    "        base_act[idx] = \\\n",
    "            np.sum(1/np.sqrt(moments[idx] - past_pres_times))\n",
    "    non_zero_activations = np.not_equal(base_act, 0)\n",
    "    base_act[non_zero_activations] = \\\n",
    "        np.log(base_act[np.not_equal(base_act, 0)])\n",
    "    \n",
    "    return base_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_times = np.linspace(0, 5000, 5)/1000\n",
    "moments = np.arange(10000)/1000\n",
    "base_act = base_activation(pres_times, moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The attentional weighting equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to base activation, a chunk's activation depends on the context in which it is needed. What counts as ''context'' within the ACT-R cognitive architecture?\n",
    "\n",
    "- context for cognitive processes is the information that is instantaneously available to the procedural module: all the buffers and the chunks that reside in them (basically, working memory, or focus of attention)\n",
    "    - this is sometimes called ''the general context''; besides the general context, there is also a specific context, relevant for partial matching\n",
    "        - partial matching is available in ```pyactr```, but we won't cover it at all\n",
    "        - see **Lebiere, Christian. 1999. The dynamics of cognition: An act-r model of cognitive arithmetic. _Kognitionswissenschaft_ 8:5â€“19** for a detailed discussion of partial matching and an example of how it can be applied to cognition and learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that chunks consist of slot-value pairs. To capture the role of context, ACT-R assumes that any chunk $V$ that appears as the value of some slot in a buffer spreads activation to\n",
    "\n",
    "- chunks in declarative memory that have $V$ as one of their values\n",
    "- chunks in declarative memory that are content-identical to $V$, i.e., they consist of the same set of slot-value pairs as $V$\n",
    "\n",
    "This context-driven boost in activation for chunks in declarative memory is known as _spreading activation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example will help shed more light on the workings of spreading activation.\n",
    "\n",
    "Suppose that only one buffer carries a chunk, say, the imaginal buffer.\n",
    "\n",
    "- the chunk in the imaginal buffer is the representation of the word _car_\n",
    "- we assume that the chunk has four slots: FORM, MEANING, CATEGORY and NUMBER\n",
    "- each of these slots, in turn, has a chunk as its value:\n",
    "    - the form\n",
    "    - the interpretation\n",
    "    - the syntactic category\n",
    "    - the morphological number \n",
    "- each of these values comes with a weight, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Car chunk in avm form with weights](figures/car_avm_with_weights.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the form _car_ has weight $W_{1}$\n",
    "- the meaning $[\\![car]\\!]$ has weight $W_{2}$\n",
    "- the syntactic category N has weight $W_{3}$\n",
    "- the number specification sg has weight $W_{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any chunk $i$ in declarative memory that shares values with the imaginal chunk (or that consists of the same slot-value pairs, but we ignore this case for expositional simplicity) receives spreading activation proportional to ($\\propto$) the weights $W_{j}$ (for $j \\in \\{1, 2, 3, 4\\}$) of the values that chunk $i$ has in common with the imaginal chunk.\n",
    "\n",
    "- chunk $i$ receives an activation boost just by virtue of containing any of the four values in the context chunk, i.e.:\n",
    "    - the form _car_ ($W_{1}$)\n",
    "    - $[\\![car]\\!]$ ($W_{2}$)\n",
    "    - N ($W_{3}$)\n",
    "    - sg ($W_{4}$)\n",
    "- intuitively, sharing a value with a context chunk (like the _car_ chunk in the imaginal buffer) 'connects' chunk $i$ in declarative memory to the context chunk\n",
    "- activation can now spread / flow along this connection, and this spreading activation is proportional to the weight $W_{j}$ (in symbols: $\\propto W_{j}$) of the connecting value\n",
    "- note that these values are themselves chunks, but we will continue to refer to them as values and explicitly call 'chunk' only:\n",
    "    - the chunk in declarative memory that receives spreading activation\n",
    "    - the context chunk that is the source of the spreading activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep insisting that spreading activation is proportional to weight $W_{j}$ ($\\propto W_{j}$), but not identical to it.\n",
    "\n",
    "- this is because chunk $i$ in declarative memory does not simply add $W_{j}$ to its activation.\n",
    "\n",
    "Every weight $W_{j}$, or _source activation_, is scaled by an _associative strength_ $S_{ji}$.\n",
    "\n",
    "- it is the product $W_{j}\\cdot S_{ji}$ that gets added to the activation of chunk $i$\n",
    "\n",
    "Intuitively, we can think of this associative strength as the strength (or the resistance, if you will) of the connection between:\n",
    "\n",
    "- chunk $i$: the activation-receiving chunk in declarative memory\n",
    "- the context chunk that is the source of spreading activation\n",
    "\n",
    "Every value shared between chunk $i$ and the context chunk 'creates' a connection along which activation $W_{j}$ can spread / flow.\n",
    "\n",
    "- this connection has a strength / resistance $S_{ji}$ specific to the value $j$ that 'created' the connection and to the activation-receiving chunk $i$\n",
    "\n",
    "In our example, we have four weights / source activations:\n",
    "\n",
    "- $W_{1}, W_{2}, W_{3}, W_{4}$\n",
    "\n",
    "We also have four corresponding associative strengths:\n",
    "\n",
    "- $S_{1i}, S_{2i}, S_{3i}, S_{4i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associative, or 'connection', strength is basically a measure of how predictive any specific value in a context chunk is of chunk $i$. This idea of 'predictive' association will make more sense in a moment when we introduce the concept of fan.\n",
    "\n",
    "In our example:\n",
    "\n",
    "- the form _car_ has weight $W_{1}$\n",
    "    - but we don't simply add that to the base activation $B_{i}$ of our chunk $i$ in declarative memory\n",
    "- we scale $W_{1}$ by the associative strength $S_{1i}$, which is the strength of the connection created by\n",
    "    - the value _car_, which resides in the FORM slot of the imaginal buffer\n",
    "    - chunk $i$, which resides in declarative memory and which has the same value _car_ in one of its slots\n",
    "- thus, the activation boost spreading to chunk $i$ in declarative memory from the value _car_ in the imaginal buffer is $W_{1}S_{1i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting total activation $A_{i}$ for any chunk $i$ in declarative memory will therefore be the sum of:\n",
    "\n",
    "- its base activation $B_{i}$, which reflects its past history of usage\n",
    "- whatever spreading activation it gets from the cognitive context, which in our example is restricted to the imaginal buffer\n",
    "\n",
    "When activation spreads along all four values of the imaginal chunk (that is, chunk $i$ in declarative has all these four values in its slots), we have:\n",
    "\n",
    "- $A_{i} = B_{i} + W_{1}S_{1i} + W_{2}S_{2i} + W_{3}S_{3i} + W_{4}S_{4i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we set the weights / source activations and associative strengths?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we to set the weights and the associative strengths? One answer that immediately comes to mind is: empirically; we set some low-information / vague priors over the weights and the associative strengths and infer them from suitable experimental data.\n",
    "\n",
    "- this is in fact what we will do (see Chapter 8 of the book)\n",
    "\n",
    "For now, we will simply discuss some reasonable default values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every chunk in a buffer that spreads activation is assumed to have a total source activation $W$ that gets evenly distributed among the values that reside in the slots of that chunk.\n",
    "\n",
    "- $W$ is by default set to $1$\n",
    "- in our example, this would mean that $W_{1} = W_{2} = W_{3} = W_{4} = \\frac{1}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default value for source activation** (summary):\n",
    "- $W_j=\\frac{W}{n}$, where\n",
    "    - $j$ goes from $1$ to the number of slots $n$ that carry a value\n",
    "    - $W$ is by default set to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn now to the associative strengths $S_{ji}$, where\n",
    "\n",
    "- $i$ is the chunk in declarative memory that receives spreading activation\n",
    "- $j$, which varies from $1$ to $n$, is a value in the cognitive context, i.e., in the buffer that spreads activation \n",
    "    - we assume that this buffer has $n$ slots that carry a value\n",
    "\n",
    "For these associative strengths $S_{ji}$, we want to capture the intuition that:\n",
    "\n",
    "- the association should be $0$ if $j$ does not associate with $i$ (it is not predictive of $i$ in any way)\n",
    "- it should be high if $j$ uniquely associates with the chunk $i$ (because $j$ is then highly predictive of $i$), which would happen if there is no other chunk in declarative memory that is associated with $j$\n",
    "- the association strength should decrease as more and more chunks in declarative memory are associated with $j$, since $j$ becomes less predictive of any of these chunks|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This intuition is captured by the following formula:\n",
    "\n",
    "- $S_{ji}\\approx \\log \\frac{\\textit{prob}(i|j)}{\\textit{prob}(i)}$\n",
    "\n",
    "That is, the strength of association between \n",
    "\n",
    "- value $j$ in a context buffer that spreads activation, and\n",
    "- chunk $i$ in declarative memory that receives activation\n",
    "\n",
    "is approximately the log probability of needing chunk $i$ from memory conditional on the fact that value $j$ is present in the buffer.\n",
    "\n",
    "- this probability is 'normalized' by the probability that chunk $i$ is unconditionally needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, this is the pointwise mutual information ($\\mathbf{pmi}$) between\n",
    "\n",
    "- the event that chunk $i$ is needed / requested from declarative memory, and\n",
    "- the event that $j$ is a value in the activation-spreading context buffer, i.e., a chunk in one of the slots of that context buffer\n",
    "\n",
    "**Pointwise mutual information** between two events $i, j$:\n",
    "\n",
    "- $\\mathbf{pmi}(i, j) = \\log\\frac{\\textit{prob}(i, j)}{\\textit{prob}(i)\\textit{prob}(j)} = \\log\\frac{\\textit{prob}(i|j)}{\\textit{prob}(i)} = \\log\\frac{\\textit{prob}(j|i)}{\\textit{prob}(j)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{pmi}$ is a symmetric measure of association between single events (not an expectation, like mutual information)\n",
    "- it can have both negative and positive values, and it is $0$ if the events are independent\n",
    "\n",
    "Understanding association strengths $S_{ji}$ in terms of the $\\mathbf{pmi}$ between the declarative memory chunk $i$ and the value $j$ in the cognitive context makes intuitive sense:\n",
    "\n",
    "- strength of association is a measure of how predictive the contextual value $j$ is of the need to retrieve chunk $i$ from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACT-R has developed a way to estimate the values in the equation above.\n",
    "\n",
    "First, for cases in which $i$ and $j$ are not associated in any way, i.e., they are independent, the joint probability $\\textit{prob}(i, j)$ is the product of the marginals $\\textit{prob}(i)\\textit{prob}(j)$, so:\n",
    "\n",
    "- $S_{ji} = \\mathbf{pmi}(i, j) = \\log\\frac{\\textit{prob}(i, j)}{\\textit{prob}(i)\\textit{prob}(j)} = \\log\\frac{\\textit{prob}(i)\\textit{prob}(j)}{\\textit{prob}(i)\\textit{prob}(j)} = \\log 1 = 0$\n",
    "\n",
    "Another way to think about this is that, if $i$ and $j$ are independent, the contextual value $j$ is not predictive at all of the need to retrieve chunk $i$ from declarative memory, so:\n",
    "\n",
    "- $\\textit{prob}(i|j) = \\frac{\\textit{prob}(i, j)}{\\textit{prob}(j)} = \\frac{\\textit{prob}(i)\\textit{prob}(j)}{\\textit{prob}(j)} = \\textit{prob}(i)$\n",
    "\n",
    "Therefore, the contextual value $j$ does not boost the activation of chunk $i$ in any way. \n",
    "\n",
    "To ensure that no activation spreads, we zero out the 'connection' strength:\n",
    "\n",
    "- $S_{ji} = \\log \\frac{\\textit{prob}(i|j)}{\\textit{prob}(i)} = \\log \\frac{\\textit{prob}(i)}{\\textit{prob}(i)} = \\log 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $j$ and $i$ are not independent, i.e., there is an association between them, so $j$ has some predictive value with regards to the need-probability of chunk $i$, the common estimate for $\\textit{prob}(i|j)$ is as follows:\n",
    "\n",
    "- $\\textit{prob}(i|j) = \\frac{1}{\\mbox{fan}_j}$, where:\n",
    "    - $\\mbox{fan}_j$ is the number of chunks associated with $j$ in declarative memory, i.e.,\n",
    "    - $\\mbox{fan}_j$ is the number of chunks that have $j$ as a value in one of their slots\n",
    "\n",
    "The intuition behind this common estimate is that a value $j$ in the cognitive context is _equally predictive_ of any chunk in declarative memory it is associated with.\n",
    "\n",
    "Basically, in the past, whenever we had value $j$ in the cognitive context, we were equally likely to need to retrieve any of the declarative memory chunks associated with $j$.\n",
    "\n",
    "This kind of assumption is unrealistic in a naturalistic, 'ecologically valid' setting, but it is probably reasonable in the context of a counterbalanced experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common estimate for $\\textit{prob}(i)$ is:\n",
    "\n",
    "- $\\textit{prob}(i) = \\frac{1}{|\\textit{dm}|}$, where:\n",
    "    - $|dm|$ is the size of declarative memory (\\textit{dm}): the number of chunks present in \\textit{dm}\n",
    "\n",
    "Again, this is extremely unrealistic since it assumes that all the chunks in declarative memory have the same history of past usage (or no history of past usage), so they have the same probability of being needed/retrieved.\n",
    "\n",
    "This estimate makes sense as a flat uniform prior used for convenience, perhaps in an experimental setting where frequentist and Bayesian posterior estimates of need probabilities for experimental items are intended to be identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two assumptions in place, associative strength $S_{ji}$ can be estimated as follows:\n",
    "\n",
    "- $S_{ji} = \\log \\frac{|\\textit{dm}|}{\\mbox{fan}_j} = \\log |\\textit{dm}| - \\log \\mbox{fan}_j$.\n",
    "\n",
    "- the dependency on a specific declarative memory chunk $i$ disappears because of the (unrealistic) uniformity assumptions built into the $\\textit{prob}(i|j)$ and $\\textit{prob}(i)$ estimates\n",
    "\n",
    "It is hard to estimate the size of declarative memory, so the minuend $\\log |\\textit{dm}|$ is often treated as a _free (hyper)parameter_ $S$:\n",
    "\n",
    "- with the requirement that $S$ should be larger than all $\\log \\mbox{fan}_j$ for any value $j$\n",
    "\n",
    "If this was not so, association could be negative in some cases, i.e., in some cases, association strength would yield negative spreading activation, decreasing (inhibiting) base activation for some items rather than simply failing to boost it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sum, the final form for associative strength that is commonly used in ACT-R modeling is as follows:\n",
    "\n",
    "**Associative strength equation between a value $j$ and a chunk $i$**:\n",
    "\n",
    "$S_{ji}=\\left\\{\n",
    "\\begin{array}{rrl}\n",
    "    S - \\log \\mbox{fan}_j && \\mbox{if }i\\mbox{ and }j\\mbox{ are associated, i.e., }i=j\\mbox{ or }j\\mbox{ is a value of }i\\\\\n",
    "     && \\\\\n",
    "    0 && \\mbox{otherwise}\\\\\n",
    "\\end{array}\\right.$\\\\\n",
    "\n",
    "- where $S$ is the maximum associative strength, a free (hyper)parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all this together with base activation, we arrive at the activation equation below. This shows how spreading activation from just one buffer affects the total activation of elements in declarative memory.\n",
    "\n",
    "**Activation equation (simplified to one buffer)**: $\\boxed{A_{i} = B_{i} + \\sum\\limits_{j=1}^{m} W_{j} S_{ji}}$\n",
    "\n",
    "- for any chunk $i$ in declarative memory and all values $j$ of the chunk in the buffer\n",
    "\n",
    "This equation has three major components:\n",
    "\n",
    "- base-level learning equation: $B_{i} = \\log \\left( \\sum\\limits_{k=1}^{n} t_{k}^{-d} \\right) = \\log \\left( \\sum\\limits_{k=1}^{n} \\frac{1}{\\sqrt{t_k}} \\right)  (\\mbox{since usually } d=0.5)$, where $t_{k}$ is the time since the $k$-th practice/presentation of chunk $i$\n",
    "- attentional weight equation: see above\n",
    "- associative strength equation: see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extending to more than one buffer is easy: we just sum up the spreading activation from all the buffers, as shown below.\n",
    "\n",
    "**Activation equation (generalized to all buffers)**: $\\boxed{A_{i} = B_{i} + \\sum\\limits_{k=1}^n\\sum\\limits_{j=1}^{m_{k}} W_{kj} S_{ji}}$\n",
    "\n",
    "- for any chunk $i$ in declarative memory, all buffers $k$ and all values $j$ of the chunk present in buffer $k$, where the chunk in buffer $k$ has $m_{k}$ slots\n",
    "\n",
    "This equation has the same three major components as the simpler one above. Differences:\n",
    " \n",
    "- We sum over all buffers $k$, from $1$ to $n$ buffers in the cognitive context\n",
    "- The weights/source activations $W_{kj}$ are indexed with both the value $j$ that is their source as well as the buffer $k$ where value $j$ is located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this a little better, think of the typical scenario in which spreading activation, i.e., source activations scaled by associative strengths, is used\n",
    "\n",
    "- the values $j$ we typically consider are values stored in the slots of the imaginal or the goal chunk\n",
    "- these buffers drive the cognitive process, so they provide a crucial part of the cognitive context in which we might want to retrieve items from memory\n",
    "- when we have a goal or an imaginal chunk, we associatively bring to salience, i.e., spread activation to, chunks in declarative memory that are associated to the imaginal or goal chunk since they might be needed\n",
    "- we operationalize this 'association' between a chunk in the cognitive context and a chunk $i$ in declarative memory in terms of the chunks being content identical (consisting of the same same set of slot-value pairs) or sharing some value $j$ in some of their slots\n",
    "- this essentially results in increasing the activation of those declarative memory chunks that are related to the current cognitive context\n",
    "    - i.e., ultimately, that are potentially relevant to the current stage of the cognitive process we are involved in\n",
    "- the associative strength $S_{ji}$ is really the probability that chunk $i$ is relevant given a cognitive context in which we attend to the value $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One intuitive way to think about the activation of chunks in declarative memory and the additive relation between base activation and spreading activation is to imagine declarative memory was a sea of darkness with small rafts, i.e., chunks, floating everywhere on it.\n",
    "\n",
    "- each raft has a small light\n",
    "- the brightness of that light indicates its total activation:\n",
    "    - the brighter that light is, the easier the raft is to find and grab\n",
    "    - that is, we can retrieve it more accurately and more quickly\n",
    "\n",
    "The light on each raft is powered by two power sources.\n",
    "\n",
    "- one of them is a rechargeable battery stored on the raft itself (well, it's more like a capacitor, but let's ignore this)\n",
    "- this reflects base activation, i.e., the history of previous usages of a chunk\n",
    "- every time we use a chunk (retrieve a raft), we plug its 'local battery' in for a quick charge\n",
    "- immediately after that, the battery will have more power, so the light will be brighter\n",
    "\n",
    "The second source of power that can increase the brightness of the light on a raft is the current cognitive context, specifically the values held in the buffers.\n",
    "\n",
    "- if these values are also stored on some of the rafts in declarative memory (that is, they are the values of some of the features of those chunks), they can act as wires delivering extra power to the lights on the rafts\n",
    "- let's focus on a specific chunk in some buffer in our cognitive context\n",
    "- each value $j$ in that chunk has a set amount of battery power (these are the source activations, i.e., the $W_{j}$ values)\n",
    "- that power gets distributed to all the rafts in declarative memory that also store that value\n",
    "- this immediately predicts that the more rafts a value in the cognitive context is connected with -- in ACT-R parlance, the higher the 'fan' of a value --, the less power it will transmit to each individual raft\n",
    "- this is called the 'fan effect'\n",
    "- the amount of power / activation that 'spreads' from the goal/imaginal buffer (or any buffer in the cognitive context that we decide to spread activation from) depends not only on the 'battery power' $W_{j}$ of each value $j$, but also on the specific 'wires' connecting the buffer and the rafts/chunks in declarative memory that share that value\n",
    "- different wires have different 'resistance' characteristics $S_{ij}$ , and the extra power boost $W_{j}$ is modulated by the 'resistance'/strength of the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go through an example.\n",
    "\n",
    "Suppose we have the word _car_ in the imaginal buffer.\n",
    "\n",
    "Also, our declarative memory consists of:\n",
    "\n",
    "- two chunks $x$ and $y$ that are singular nouns (say, _book_ and _pen_)\n",
    "- one chunk $z$ that is a plural noun (say, _books_)\n",
    "\n",
    "The singular nouns $x, y$ have two values in common with the _car_ chunk in the imaginal buffer:\n",
    "\n",
    "- the singular number\n",
    "- the noun category\n",
    "\n",
    "The plural noun $z$ has only one value in common with the _car_ chunk:\n",
    "\n",
    "- the noun category\n",
    "\n",
    "The activation of the plural noun $z$ is calculated below. Recall that $j$ are the values of the _car_ chunk in the imaginal buffer:\n",
    "\n",
    "- $j=1$ for the form slot\n",
    "- $j=2$ for the meaning slot\n",
    "- $j=3$ for the syntactic category slot\n",
    "- $j=4$ for the number morphology slot\n",
    "\n",
    "Since there are 4 total slots in the imaginal buffer chunk, the source activations are all set to $\\frac{1}{4}$ (see above, with $W = 1, n = 4$).\n",
    "\n",
    "Turning to association strengths, we note that only the value in the syntactic category slot (i.e., noun/N) spreads activation. This means that the association strengths for all the other values are zero:\n",
    "\n",
    "- $S_{1z} = S_{2z} = S_{4z} = 0$\n",
    "\n",
    "The fan of the value in the syntactic category slot, namely $\\mbox{fan}_3$, is $4$:\n",
    "\n",
    "- the value is noun/N,  and there are four nouns total in declarative memory: $x, y, z$ and, we assume, also the _car_ chunk currently in the imaginal buffer\n",
    "\n",
    "The calculation, therefore, proceeds as follows:\n",
    "\n",
    "$$\\begin{array}[t]{lcl}\n",
    "        A_{z}&=&B_{z}+\\sum\\limits_{j=1}^{m} W_{j} S_{jz}\\\\\n",
    "        &=&B_z+W_1S_{1z}+W_2S_{2z}+W_3S_{3z}+W_4S_{4z}\\\\\n",
    "        &=&B_z+\\frac{1}{4}\\cdot S_{1z}+\\frac{1}{4}\\cdot S_{2z}+\\frac{1}{4}\\cdot S_{3z}+\\frac{1}{4}\\cdot S_{4z}\\\\\n",
    "        &=&B_z+\\frac{1}{4}\\cdot 0+\\frac{1}{4}\\cdot 0+\\frac{1}{4}\\cdot (S-\\log \\mbox{fan}_{3})+\\frac{1}{4}\\cdot 0\\\\\n",
    "        &=&B_z+\\frac{1}{4}\\cdot (S-\\log 4)\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, the activation of the singular noun $x$ proceeds as shown below.\n",
    "\n",
    "This time, the singular receives spreading activation both from the syntactic category value (N) and from the number specification (sg). \n",
    "\n",
    "- the activation spreading from the number value is higher than the one spreading from the syntactic category value because there are 4 nouns total ($\\mbox{fan}_{3} = 4$), but only 3 of them are singular ($\\mbox{fan}_{4} = 3$)\n",
    "- this makes intuitive sense: values that appear only in a handful of chunks are more predictive of these chunks, and should boost their activation more than values that are more frequent and therefore less discriminatory\n",
    "\n",
    "$$\\begin{array}[t]{lcl}\n",
    "        A_{x}&=&B_{x}+\\sum\\limits_{j=1}^{m} W_{j} S_{jx}\\\\\n",
    "        &=&B_x+W_1S_{1z}+W_2S_{2z}+W_3S_{3x}+W_4S_{4x}\\\\\n",
    "        &=&B_z+\\frac{1}{4}\\cdot S_{1z}+\\frac{1}{4}\\cdot S_{2z}+\\frac{1}{4}\\cdot S_{3x}+\\frac{1}{4}\\cdot S_{4x}\\\\\n",
    "        &=&B_x+\\frac{1}{4}\\cdot 0+\\frac{1}{4}\\cdot 0+\\frac{1}{4}\\cdot (S-\\log \\mbox{fan}_{3})+\\frac{1}{4}\\cdot (S-\\log \\mbox{fan}_{4})\\\\\n",
    "        &=&B_x+\\frac{1}{4}\\cdot (S-\\log 4)+\\frac{1}{4}\\cdot (S-\\log 3)\\\\\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
